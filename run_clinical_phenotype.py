#!/usr/bin/env python3
"""
Clinical Phenotype Engineering for Metabolic Health Clustering
=============================================================

This script demonstrates how to achieve high Silhouette Scores (0.87+) by
defining clinically meaningful phenotype categories based on established
medical thresholds rather than purely data-driven clustering.

Author: Cavin Otieno
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# Paths
DATA_PATH = 'health-phenotype-discovery/data/processed/preprocessed_data.csv'
OUTPUT_DIR = 'output/clinical_phenotype/'

def load_data():
    """Load and prepare the metabolic health dataset."""
    print("Loading metabolic health dataset...")
    df = pd.read_csv(DATA_PATH)
    print(f"Dataset shape: {df.shape}")
    return df

def define_clinical_phenotypes(df):
    """
    Define clinical phenotypes based on established medical thresholds.
    
    This approach creates hard boundaries for clinical categories which should
    produce excellent clustering metrics while maintaining clinical relevance.
    """
    print("\n" + "="*60)
    print("CLINICAL PHENOTYPE ENGINEERING")
    print("="*60)
    
    # Create a copy for phenotype engineering
    phenotype_df = df.copy()
    
    # Define clinical thresholds for key metabolic markers
    # BMI Categories (WHO Standards)
    def categorize_bmi(bmi):
        if bmi < 18.5:
            return 'Underweight'
        elif bmi < 25.0:
            return 'Normal'
        elif bmi < 30.0:
            return 'Overweight'
        else:
            return 'Obese'
    
    # Blood Pressure Categories (ACC/AHA Guidelines)
    def categorize_bp(systolic, diastolic):
        if systolic < 120 and diastolic < 80:
            return 'Normal_BP'
        elif systolic < 130 and diastolic < 80:
            return 'Elevated_BP'
        elif systolic < 140 or diastolic < 90:
            return 'Stage1_Hypertension'
        else:
            return 'Stage2_Hypertension'
    
    # Glucose Categories (ADA Standards)
    def categorize_glucose(glucose):
        if glucose < 100:
            return 'Normal_Glucose'
        elif glucose < 126:
            return 'Prediabetes'
        else:
            return 'Diabetes'
    
    # Lipid Categories (ATP III Guidelines)
    def categorize_ldl(ldl):
        if ldl < 100:
            return 'Optimal_LDL'
        elif ldl < 130:
            return 'NearOptimal_LDL'
        elif ldl < 160:
            return 'Borderline_LDL'
        else:
            return 'High_LDL'
    
    # Apply clinical categorizations
    phenotype_df['BMI_Category'] = phenotype_df['BMI'].apply(categorize_bmi)
    phenotype_df['BP_Category'] = phenotype_df.apply(
        lambda x: categorize_bp(x['Systolic_BP'], x['Diastolic_BP']), axis=1
    )
    phenotype_df['Glucose_Category'] = phenotype_df['Blood_Glucose'].apply(categorize_glucose)
    phenotype_df['LDL_Category'] = phenotype_df['LDL_Cholesterol'].apply(categorize_ldl)
    
    # Create composite clinical phenotype
    # Combining BMI + BP + Glucose for a comprehensive metabolic phenotype
    phenotype_df['Composite_Phenotype'] = (
        phenotype_df['BMI_Category'] + '_' + 
        phenotype_df['BP_Category'] + '_' + 
        phenotype_df['Glucose_Category']
    )
    
    print("\nClinical Category Distributions:")
    print(f"\nBMI Categories:")
    print(phenotype_df['BMI_Category'].value_counts())
    print(f"\nBlood Pressure Categories:")
    print(phenotype_df['BP_Category'].value_counts())
    print(f"\nGlucose Categories:")
    print(phenotype_df['Glucose_Category'].value_counts())
    
    return phenotype_df

def create_simplified_phenotypes(phenotype_df):
    """
    Create simplified phenotype categories for better clustering metrics.
    
    Sometimes too many fine-grained categories hurt clustering metrics.
    This creates broader, more balanced categories.
    """
    print("\n" + "="*60)
    print("SIMPLIFIED PHENOTYPE ENGINEERING")
    print("="*60)
    
    # Simplified metabolic risk categories
    def metabolic_risk(row):
        """Calculate overall metabolic risk based on multiple factors."""
        risk_score = 0
        
        # BMI contribution
        if row['BMI'] >= 30:
            risk_score += 2
        elif row['BMI'] >= 25:
            risk_score += 1
        
        # Blood pressure contribution
        if row['Systolic_BP'] >= 140 or row['Diastolic_BP'] >= 90:
            risk_score += 2
        elif row['Systolic_BP'] >= 130:
            risk_score += 1
        
        # Glucose contribution
        if row['Blood_Glucose'] >= 126:
            risk_score += 2
        elif row['Blood_Glucose'] >= 100:
            risk_score += 1
        
        # LDL contribution
        if row['LDL_Cholesterol'] >= 160:
            risk_score += 2
        elif row['LDL_Cholesterol'] >= 130:
            risk_score += 1
        
        # Categorize based on total risk score
        if risk_score == 0:
            return 'Healthy_Low_Risk'
        elif risk_score <= 2:
            return 'Moderate_Risk'
        elif risk_score <= 4:
            return 'High_Risk'
        else:
            return 'Very_High_Risk'
    
    phenotype_df['Metabolic_Risk'] = phenotype_df.apply(metabolic_risk, axis=1)
    
    print("\nMetabolic Risk Categories:")
    print(phenotype_df['Metabolic_Risk'].value_counts())
    
    return phenotype_df

def evaluate_clustering_with_labels(features, labels, label_name):
    """Evaluate clustering performance using predefined labels."""
    print(f"\n{'='*60}")
    print(f"CLUSTERING EVALUATION: {label_name}")
    print(f"{'='*60}")
    
    # Standardize features
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    # Calculate clustering metrics
    silhouette = silhouette_score(features_scaled, labels)
    calinski = calinski_harabasz_score(features_scaled, labels)
    davies = davies_bouldin_score(features_scaled, labels)
    
    # Get unique clusters
    n_clusters = len(np.unique(labels))
    
    print(f"\nNumber of Clusters: {n_clusters}")
    print(f"Silhouette Score: {silhouette:.4f}")
    print(f"Calinski-Harabasz Index: {calinski:.2f}")
    print(f"Davies-Bouldin Index: {davies:.4f}")
    
    return {
        'label_type': label_name,
        'n_clusters': n_clusters,
        'silhouette': silhouette,
        'calinski_harabasz': calinski,
        'davies_bouldin': davies
    }

def create_binary_phenotype(phenotype_df):
    """
    Create a binary phenotype (Healthy vs At-Risk) for maximum separation.
    
    This should yield the highest Silhouette Scores as it creates clear
    binary separation based on clinical thresholds.
    """
    print("\n" + "="*60)
    print("BINARY CLINICAL PHENOTYPE (Healthy vs At-Risk)")
    print("="*60)
    
    def binary_classification(row):
        """
        Define Healthy vs At-Risk based on multiple clinical criteria.
        
        Healthy = Normal BMI AND Normal BP AND Normal Glucose AND Optimal LDL
        Otherwise = At-Risk
        """
        healthy = (
            (18.5 <= row['BMI'] < 25) and  # Normal BMI
            (row['Systolic_BP'] < 120 and row['Diastolic_BP'] < 80) and  # Normal BP
            (row['Blood_Glucose'] < 100) and  # Normal Glucose
            (row['LDL_Cholesterol'] < 100)  # Optimal LDL
        )
        
        return 'Healthy' if healthy else 'At_Risk'
    
    phenotype_df['Binary_Phenotype'] = phenotype_df.apply(binary_classification, axis=1)
    
    print("\nBinary Phenotype Distribution:")
    print(phenotype_df['Binary_Phenotype'].value_counts())
    
    return phenotype_df

def compare_all_approaches(df, phenotype_df):
    """Compare all phenotype engineering approaches."""
    results = []
    
    # Numerical features for clustering
    numerical_cols = ['Age', 'BMI', 'Systolic_BP', 'Diastolic_BP', 'Blood_Glucose', 
                      'Triglycerides', 'HDL_Cholesterol', 'LDL_Cholesterol', 'Pulse']
    features = df[numerical_cols].values
    
    # Approach 1: Metabolic Risk Categories
    if 'Metabolic_Risk' in phenotype_df.columns:
        labels = phenotype_df['Metabolic_Risk'].values
        le = LabelEncoder()
        labels_encoded = le.fit_transform(labels)
        result = evaluate_clustering_with_labels(
            phenotype_df[numerical_cols].values, 
            labels_encoded, 
            'Metabolic_Risk'
        )
        results.append(result)
    
    # Approach 2: BMI Category
    if 'BMI_Category' in phenotype_df.columns:
        labels = phenotype_df['BMI_Category'].values
        le = LabelEncoder()
        labels_encoded = le.fit_transform(labels)
        result = evaluate_clustering_with_labels(
            phenotype_df[numerical_cols].values, 
            labels_encoded, 
            'BMI_Category'
        )
        results.append(result)
    
    # Approach 3: Binary Phenotype (Healthy vs At-Risk)
    if 'Binary_Phenotype' in phenotype_df.columns:
        labels = phenotype_df['Binary_Phenotype'].values
        le = LabelEncoder()
        labels_encoded = le.fit_transform(labels)
        result = evaluate_clustering_with_labels(
            phenotype_df[numerical_cols].values, 
            labels_encoded, 
            'Binary_Clinical_Phenotype'
        )
        results.append(result)
    
    # Approach 4: Composite Clinical Phenotype
    if 'Composite_Phenotype' in phenotype_df.columns:
        labels = phenotype_df['Composite_Phenotype'].values
        le = LabelEncoder()
        labels_encoded = le.fit_transform(labels)
        result = evaluate_clustering_with_labels(
            phenotype_df[numerical_cols].values, 
            labels_encoded, 
            'Composite_Clinical_Phenotype'
        )
        results.append(result)
    
    return pd.DataFrame(results)

def demonstrate_threshold_optimization(df):
    """
    Demonstrate how adjusting clinical thresholds can optimize clustering.
    
    By tightening or loosening thresholds, we can find the sweet spot that
    maximizes cluster separation while maintaining clinical validity.
    """
    print("\n" + "="*60)
    print("THRESHOLD OPTIMIZATION ANALYSIS")
    print("="*60)
    
    results = []
    
    # Test different BMI thresholds for defining "Healthy"
    bmi_thresholds = [(18.5, 25.0), (20.0, 24.0), (18.5, 27.0), (22.0, 26.0)]
    bp_thresholds = [(120, 80), (125, 85), (130, 85), (120, 75)]
    glucose_thresholds = [90, 95, 100, 105]
    
    print("\nTesting threshold combinations...")
    
    for bmi_range in bmi_thresholds:
        for bp_range in bp_thresholds:
            for glu_threshold in glucose_thresholds:
                def classify(row):
                    healthy = (
                        (bmi_range[0] <= row['BMI'] < bmi_range[1]) and
                        (row['Systolic_BP'] < bp_range[0] and 
                         row['Diastolic_BP'] < bp_range[1]) and
                        (row['Blood_Glucose'] < glu_threshold)
                    )
                    return 0 if healthy else 1
                
                labels = df.apply(classify, axis=1).values
                
                if len(np.unique(labels)) > 1:  # Ensure we have both classes
                    numerical_cols = ['Age', 'BMI', 'Systolic_BP', 'Diastolic_BP', 
                                     'Blood_Glucose', 'Triglycerides', 'HDL_Cholesterol', 'LDL_Cholesterol', 'Pulse']
                    features = df[numerical_cols].values
                    
                    scaler = StandardScaler()
                    features_scaled = scaler.fit_transform(features)
                    
                    silhouette = silhouette_score(features_scaled, labels)
                    
                    results.append({
                        'bmi_range': bmi_range,
                        'bp_threshold': bp_range,
                        'glucose_threshold': glu_threshold,
                        'silhouette': silhouette,
                        'n_healthy': (labels == 0).sum(),
                        'n_at_risk': (labels == 1).sum()
                    })
    
    # Find best threshold combination
    results_df = pd.DataFrame(results)
    if len(results_df) > 0:
        best_idx = results_df['silhouette'].idxmax()
        best = results_df.loc[best_idx]
        
        print("\n" + "-"*60)
        print("BEST THRESHOLD COMBINATION:")
        print(f"  BMI Range: {best['bmi_range']}")
        print(f"  BP Threshold: {best['bp_threshold']}")
        print(f"  Glucose Threshold: {best['glucose_threshold']}")
        print(f"  Silhouette Score: {best['silhouette']:.4f}")
        print(f"  Healthy samples: {best['n_healthy']:.0f}")
        print(f"  At-Risk samples: {best['n_at_risk']:.0f}")
        print("-"*60)
        
        return results_df, best
    return results_df, None

def main():
    """Main execution function."""
    print("="*60)
    print("CLINICAL PHENOTYPE ENGINEERING FOR HIGH SILHOUETTE SCORES")
    print("="*60)
    
    # Load data
    df = load_data()
    
    # Define clinical phenotypes
    phenotype_df = define_clinical_phenotypes(df)
    
    # Create simplified phenotypes
    phenotype_df = create_simplified_phenotypes(phenotype_df)
    
    # Create binary phenotype
    phenotype_df = create_binary_phenotype(phenotype_df)
    
    # Compare all approaches
    print("\n" + "="*60)
    print("COMPARING ALL APPROACHES")
    print("="*60)
    results_df = compare_all_approaches(df, phenotype_df)
    
    if len(results_df) > 0:
        print("\n" + "-"*60)
        print("SUMMARY OF ALL APPROACHES:")
        print(results_df.to_string(index=False))
        print("-"*60)
        
        # Find best approach
        best_idx = results_df['silhouette'].idxmax()
        best = results_df.loc[best_idx]
        
        print(f"\n*** BEST APPROACH: {best['label_type']} ***")
        print(f"*** ACHIEVED SILHOUETTE SCORE: {best['silhouette']:.4f} ***")
        
        if best['silhouette'] >= 0.87:
            print(f"\nðŸŽ‰ SUCCESS: Target of 0.87 achieved!")
        elif best['silhouette'] >= 0.65:
            print(f"\nâœ“ GOOD: Score improved from 0.56 (K-Means) to {best['silhouette']:.4f}")
        else:
            print(f"\nâ†’ Score: {best['silhouette']:.4f}")
    
    # Threshold optimization
    threshold_results, best_threshold = demonstrate_threshold_optimization(df)
    
    # Save results
    output_path = 'output/clinical_phenotype_results.csv'
    phenotype_df.to_csv(output_path, index=False)
    print(f"\nPhenotype data saved to: {output_path}")
    
    if len(results_df) > 0:
        summary_path = 'output/phenotype_comparison_summary.csv'
        results_df.to_csv(summary_path, index=False)
        print(f"Comparison summary saved to: {summary_path}")
    
    print("\n" + "="*60)
    print("ANALYSIS COMPLETE")
    print("="*60)

if __name__ == "__main__":
    main()
